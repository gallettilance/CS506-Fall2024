{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 03\n",
    "\n",
    "Name: Jae Hong Lee\n",
    "UID: U27565203\n",
    "\n",
    "### Topics\n",
    "\n",
    "- Intro to DS\n",
    "\n",
    "### Linear Algebra Review\n",
    "\n",
    "If you need a linear algebra review, please read through the [following pdf](https://github.com/gallettilance/CS506-Fall2024/raw/main/lecture_02/lecture_02_linear_algebra_review.pdf) before next class\n",
    "\n",
    "### Participation\n",
    "\n",
    "Please fill out the [following form](https://forms.gle/XHay822QrZvByirM8)\n",
    "\n",
    "### Intro to Data Science (ungraded)\n",
    "\n",
    "a) what property must a hypothesis have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Testability (Falsifiability)\n",
    "A hypothesis should be testable through experiments or observations. It must be possible to confirm or refute the hypothesis based on empirical data.\n",
    "\n",
    "### 2. Specificity\n",
    "The hypothesis should be specific enough to make clear predictions. It should define the expected outcome in a way that can be measured and analyzed.\n",
    "\n",
    "### 3. Simplicity (Occam's Razor)\n",
    "A good hypothesis should be as simple as possible while still explaining the phenomenon. This principle, often referred to as Occam's Razor, suggests that the simplest explanation is usually the best.\n",
    "\n",
    "### 4. Relevance\n",
    "The hypothesis should be relevant to the research question or problem being addressed. It should contribute meaningfully to understanding the subject matter.\n",
    "\n",
    "### 5. Consistency\n",
    "The hypothesis should be consistent with existing knowledge and theories unless it provides compelling evidence to challenge those theories.\n",
    "\n",
    "### 6. Generality\n",
    "A hypothesis should have the potential to apply to a broader context beyond the specific instances tested, allowing for generalization of findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) what examples would you have wanted to try?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Health and Medicine\n",
    "\n",
    "Hypothesis: \"Regular physical exercise reduces the incidence of depression among adults.\"\n",
    "\n",
    "Experiment: Conduct a longitudinal study comparing mental health outcomes between active and sedentary groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Given the hypothesis (x, 2x, 3x), for each of the following, determine whether they are positive or negative examples:\n",
    "\n",
    "- (2, 4, 6)\n",
    "- (6, 8 , 10)\n",
    "- (1, 3, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- positive\n",
    "- negatice\n",
    "- negative"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Describe steps of a Data Science Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Define the Problem\n",
    "Identify Objectives: Clearly outline the problem you want to solve or the question you want to answer.\n",
    "Stakeholder Engagement: Discuss with stakeholders to understand their needs and expectations.\n",
    "\n",
    "#### 2. Data Collection\n",
    "Data Sources: Identify and gather data from relevant sources, such as databases, APIs, web scraping, or surveys.\n",
    "Data Types: Collect structured (e.g., SQL databases) and unstructured data (e.g., text, images).\n",
    "\n",
    "#### 3. Data Cleaning and Preparation\n",
    "Data Cleaning: Handle missing values, outliers, and duplicates. Ensure data quality by validating and correcting errors.\n",
    "Data Transformation: Convert raw data into a suitable format for analysis, including normalization, scaling, and encoding categorical variables.\n",
    "\n",
    "#### 4. Exploratory Data Analysis (EDA)\n",
    "Data Visualization: Use graphs and charts to visualize data distributions and relationships.\n",
    "Statistical Analysis: Analyze data using statistical methods to identify patterns, trends, and insights.\n",
    "\n",
    "#### 5. Feature Engineering\n",
    "Feature Selection: Identify the most relevant features (variables) that contribute to the target variable.\n",
    "Feature Creation: Create new features from existing ones to improve model performance.\n",
    "\n",
    "#### 6. Model Building\n",
    "Select Algorithms: Choose appropriate algorithms based on the problem type (e.g., regression, classification).\n",
    "Train Models: Split the data into training and testing sets, and train models using the training data.\n",
    "\n",
    "#### 7. Model Evaluation\n",
    "Performance Metrics: Evaluate model performance using metrics such as accuracy, precision, recall, F1 score, or RMSE.\n",
    "Cross-Validation: Use techniques like k-fold cross-validation to ensure the model's robustness.\n",
    "\n",
    "#### 8. Hyperparameter Tuning\n",
    "Optimize Parameters: Adjust model parameters to enhance performance using techniques like grid search or random search.\n",
    "\n",
    "#### 9. Deployment\n",
    "Model Deployment: Deploy the model in a production environment for real-world use.\n",
    "Integration: Integrate the model with existing systems or applications.\n",
    "\n",
    "#### 10. Monitoring and Maintenance\n",
    "Monitor Performance: Continuously track the modelâ€™s performance to ensure it remains effective over time.\n",
    "Update Models: Retrain and update the model as new data becomes available or when performance declines.\n",
    "\n",
    "#### 11. Communicate Results\n",
    "Reporting: Present findings and insights to stakeholders using visualizations and clear explanations.\n",
    "Actionable Insights: Provide recommendations based on the analysis to guide decision-making.\n",
    "\n",
    "#### Summary\n",
    "This workflow is iterative, meaning that insights gained from later stages can lead back to earlier stages for refinement and improvement. Data Science is a dynamic field, and these steps can vary depending on the specific project and organizational needs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Give a real world example for each of the following data types:\n",
    "\n",
    "- record\n",
    "- graph\n",
    "- image\n",
    "- text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Record\n",
    "#### Example: A customer profile in a retail database.\n",
    "##### Description: A record might include fields such as customer ID, name, email address, phone number, purchase history, and loyalty points. Each record represents a unique customer and is stored in a structured format, typically in a database.\n",
    "\n",
    "### 2. Graph\n",
    "#### Example: Social network connections.\n",
    "##### Description: In a social media platform like Facebook, users are represented as nodes, and their connections (friendships) are represented as edges. This graph structure allows for complex queries about relationships, such as finding the shortest path between two users or identifying clusters of friends.\n",
    "\n",
    "### 3. Image\n",
    "#### Example: Medical imaging (e.g., X-ray scans).\n",
    "##### Description: X-ray images are used in healthcare to visualize the internal structures of the body. These images can be analyzed for diagnosing conditions such as fractures or tumors. They are typically stored in formats like DICOM (Digital Imaging and Communications in Medicine).\n",
    "\n",
    "### 4. Text\n",
    "#### Example: Customer reviews on an e-commerce website.\n",
    "##### Description: Text data collected from customer reviews can include feedback, ratings, and comments about products. This text can be analyzed using natural language processing (NLP) techniques to gain insights into customer sentiment and improve product offerings."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) Give a real world example of unsupervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customer Segmentation\n",
    "Description: In this scenario, a retail company wants to understand its customer base better without predefined labels or categories. They collect various data points, such as purchase history, browsing behavior, demographics, and customer feedback.\n",
    "\n",
    "## Process:\n",
    "Data Collection: The company gathers data on customer interactions, including what products they buy, how often they shop, and their demographic information (age, gender, location).\n",
    "\n",
    "### Feature Selection: Relevant features for clustering might include:\n",
    "\n",
    "Total spend \n",
    "- Frequency of purchases \n",
    "- Types of products purchased\n",
    "- Time spent on the website\n",
    "- Applying Unsupervised Learning Algorithms:\n",
    "\n",
    "The company uses clustering algorithms, such as K-means or DBSCAN, to identify groups of similar customers based on the selected features.\n",
    "\n",
    "he algorithm groups customers into clusters, where each cluster represents a segment of customers with similar behaviors or characteristics.\n",
    "\n",
    "### Analysis of Results:\n",
    "\n",
    "The marketing team analyzes the resulting clusters to understand different customer segments. For example, they may find:\n",
    "\n",
    "- A segment of high-value customers who frequently buy luxury items.\n",
    "- A group of budget-conscious shoppers who prefer discounts and sales.\n",
    " - New customers who are still exploring the product range.\n",
    "#### Actionable Insights:\n",
    "\n",
    "Based on these insights, the company can tailor marketing strategies to each segment, such as targeted promotions, personalized recommendations, and more effective communication strategies.\n",
    "\n",
    "## Conclusion:\n",
    "This example illustrates how unsupervised learning helps businesses derive insights from unlabelled data, enabling them to make informed decisions and enhance their marketing efforts without the need for predefined outcomes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g) Give a real world example of supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Email Spam Detection\n",
    "Description: In this scenario, an email service provider wants to automatically classify incoming emails as either \"spam\" or \"not spam.\" This involves training a model using labeled data where emails are already categorized.\n",
    "\n",
    "## Process:\n",
    "### Data Collection:\n",
    "\n",
    "The provider collects a dataset of emails that have been labeled as \"spam\" or \"not spam\" (also known as \"ham\"). Each email includes various features, such as:\n",
    "- Subject line\n",
    "- Sender's email address\n",
    "- Email content (text)\n",
    "- Presence of links or attachments\n",
    "- Feature Selection:\n",
    "\n",
    "#### Relevant features might include:\n",
    "\n",
    "Frequency of certain keywords (e.g., \"free,\" \"win,\" \"limited time\")\n",
    "Number of links in the email\n",
    "Length of the email\n",
    "Presence of attachments\n",
    "\n",
    "#### Training the Model:\n",
    "\n",
    "A supervised learning algorithm, such as a decision tree, support vector machine (SVM), or logistic regression, is used to train the model on the labeled dataset.\n",
    "The model learns the patterns and characteristics that distinguish spam emails from non-spam emails based on the provided features.\n",
    "#### Model Evaluation:\n",
    "\n",
    "The trained model is tested on a separate dataset of labeled emails to evaluate its performance. Metrics like accuracy, precision, recall, and F1 score are calculated to measure how well the model classifies emails.\n",
    "\n",
    "#### Deployment:\n",
    "\n",
    "Once the model is trained and evaluated, it is deployed in the email system. As new emails arrive, the model classifies them as \"spam\" or \"not spam\" based on the learned patterns.\n",
    "\n",
    "#### Continuous Improvement:\n",
    "\n",
    "The model can be continuously improved by retraining it with new labeled emails to adapt to changing spam tactics.\n",
    "\n",
    "## Conclusion:\n",
    "This example illustrates how supervised learning uses labeled data to train a model that can make accurate predictions on new, unseen data. Email spam detection is a practical application that enhances user experience by filtering unwanted messages."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
