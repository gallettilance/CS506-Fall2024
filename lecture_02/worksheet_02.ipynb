{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 03\n",
    "\n",
    "Name:  Srishti Jain\n",
    "\n",
    "UID: U10424126\n",
    "\n",
    "### Topics\n",
    "\n",
    "- Intro to DS\n",
    "\n",
    "### Linear Algebra Review\n",
    "\n",
    "If you need a linear algebra review, please read through the [following pdf](https://github.com/gallettilance/CS506-Fall2024/raw/main/lecture_02/lecture_02_linear_algebra_review.pdf) before next class\n",
    "\n",
    "### Participation\n",
    "\n",
    "Please fill out the [following form](https://forms.gle/XHay822QrZvByirM8)\n",
    "\n",
    "### Intro to Data Science (ungraded)\n",
    "\n",
    "a) what property must a hypothesis have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A hypothesis must have the following key properties - \n",
    "\n",
    "1. Testability - A hypothesis must be formulated in such a way that it can be tested or validated through experimentation, observation or data analysis. This means it should be possible to collect data or evidence that either supports or refutes the hypothesis.\n",
    "\n",
    "2. Falsifiability - A hypothesis must be falsifiable, there should be a possible outcome or observation that can demonstrate the hypothesis to be false. If a hypothesis cannot be proven wrong under any circumstance, it is not considered scientifically valid.\n",
    "\n",
    "3. Specificity - A good hypothesis should be specific, clearly stating the expected relationship between variables or the outcome it predicts. Vague or overly broad hypotheses are difficult to test or falsify.\n",
    "\n",
    "4. Consistency - A hypothesis should be consistent with existing theories, knowledge, or observations. While it can challenge established understanding, it must still logically align with the current state of knowledge or provide a compelling reason for why an existing theory might be incorrect.\n",
    "\n",
    "5. Simplicity (Parsimony) - When multiple hypotheses explain the same phenomenon, the simplest one — the one that makes the fewest assumptions — is generally preferred. This is often referred to as \"Occam's Razor.\"\n",
    "\n",
    "6. Relevance - The hypothesis should be relevant to the research question or problem being studied. It should provide meaningful insights or explanations that advance knowledge in a specific field.\n",
    "\n",
    "By ensuring these properties, a hypothesis becomes a valuable tool in scientific inquiry, guiding the research process and enabling systematic investigation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) what examples would you have wanted to try?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypothesis - \"Urban areas with more green spaces have lower average temperatures during summer than those with less greenery.\n",
    "\n",
    "The hypothesis can be tested by comparing temperature data from urban areas with varying amounts of green space. It is specific, testable, falsifiable (if no temperature difference is found, the hypothesis is disproven), and relevant for urban planning and climate research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Given the hypothesis (x, 2x, 3x), for each of the following, determine whether they are positive or negative examples:\n",
    "\n",
    "- (2, 4, 6)\n",
    "- (6, 8 , 10)\n",
    "- (1, 3, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2, 4, 6) - Positive example\n",
    "\n",
    "(6, 8, 10) - Negative example\n",
    "\n",
    "(1, 3, 5) - Negative example"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Describe steps of a Data Science Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Data Science workflow typically involves a series of structured steps to solve a data-driven problem. Here’s an overview of the main steps -\n",
    "\n",
    "1. Define the Problem\n",
    "\n",
    "* Objective: Clearly define the problem you want to solve and the goals you aim to achieve.\n",
    "\n",
    "* Steps\n",
    "    * Understand the business or research question.\n",
    "    * Identify the stakeholders and understand their needs.\n",
    "    * Determine the desired outcomes (e.g., improve customer retention, predict stock prices, classify images).\n",
    "\n",
    "\n",
    "2. Collect Data\n",
    "\n",
    "* Objective: Gather the data required to solve the problem.\n",
    "\n",
    "* Steps:\n",
    "\n",
    "    * Identify the data sources (e.g., databases, APIs, web scraping, sensors).\n",
    "    * Collect or extract data from various sources.\n",
    "    * Ensure data privacy, legality, and ethical considerations are met.\n",
    "\n",
    "3. Data Cleaning and Preprocessing\n",
    "\n",
    "* Objective: Prepare the data for analysis by handling missing, incorrect, or irrelevant data.\n",
    "\n",
    "* Steps:\n",
    "\n",
    "    * Handle missing values (e.g., remove, fill, or interpolate).\n",
    "    * Correct errors and inconsistencies in the data.\n",
    "    * Remove duplicates and irrelevant data.\n",
    "    * Normalize or standardize data (e.g., scaling numerical features, encoding categorical variables).\n",
    "    * Transform data into a suitable format (e.g., converting data types, handling date-time formats).\n",
    "\n",
    "4. Exploratory Data Analysis (EDA)\n",
    "\n",
    "* Objective: Understand the data, discover patterns, and form hypotheses.\n",
    "\n",
    "* Steps:\n",
    "\n",
    "    * Visualize data distributions, relationships, and trends (e.g., histograms, scatter plots).\n",
    "    * Calculate summary statistics (e.g., mean, median, variance, correlation).\n",
    "    * Identify outliers, anomalies, or unusual patterns.\n",
    "    * Formulate hypotheses or questions based on insights from the data.\n",
    "\n",
    "5. Feature Engineering\n",
    "\n",
    "* Objective: Create or select the most relevant features (variables) for the model.\n",
    "\n",
    "* Steps:\n",
    "\n",
    "    * Create new features based on domain knowledge (e.g., aggregations, ratios, polynomial features).\n",
    "    * Transform or encode categorical variables (e.g., one-hot encoding, label encoding).\n",
    "    * Select important features using methods like correlation analysis, feature importance scores, or dimensionality reduction techniques (e.g., PCA).\n",
    "\n",
    "6. Model Selection\n",
    "\n",
    "* Objective: Choose appropriate algorithms that align with the problem type and data characteristics.\n",
    "\n",
    "* Steps:\n",
    "\n",
    "    * Determine the type of problem (e.g., classification, regression, clustering).\n",
    "    * Select algorithms that are suitable for the problem (e.g., decision trees, logistic regression, k-means).\n",
    "    * Consider the model’s interpretability, computational efficiency, and scalability.\n",
    "\n",
    "7. Model Training\n",
    "\n",
    "* Objective: Train the chosen model(s) on the prepared dataset.\n",
    "\n",
    "* Steps:\n",
    "\n",
    "    * Split the data into training, validation, and test sets (e.g., 70-20-10 or 80-20).\n",
    "    * Train the model on the training set using appropriate algorithms.\n",
    "    * Optimize hyperparameters using techniques like cross-validation or grid search.\n",
    "\n",
    "8. Model Evaluation\n",
    "\n",
    "* Objective: Assess the performance of the model to ensure it meets the desired criteria.\n",
    "\n",
    "* Steps:\n",
    "\n",
    "    * Evaluate the model on the validation and test sets using relevant metrics (e.g., accuracy, precision, recall, F1-score, AUC).\n",
    "    * Compare model performance against baseline models.\n",
    "    * Check for overfitting or underfitting (e.g., analyze training vs. validation performance).\n",
    "\n",
    "9. Model Deployment\n",
    "\n",
    "* Objective: Integrate the model into a production environment to make it accessible to end-users.\n",
    "\n",
    "* Steps:\n",
    "\n",
    "    * Prepare the model for deployment (e.g., export model files, create an API).\n",
    "    * Deploy the model on a server, cloud service, or edge device.\n",
    "    * Ensure scalability, reliability, and security of the deployed model.\n",
    "10. Monitor and Maintain the Model\n",
    "\n",
    "* Objective: Continuously monitor the model's performance and update it as needed.\n",
    "\n",
    "* Steps:\n",
    "\n",
    "    * Monitor model predictions in real-time for accuracy and performance.\n",
    "    * Identify and handle model drift (changes in input data or target distribution).\n",
    "    * Regularly update or retrain the model with new data.\n",
    "\n",
    "11. Communicate Results\n",
    "\n",
    "* Objective: Present insights, findings, and recommendations to stakeholders.\n",
    "\n",
    "* Steps:\n",
    "\n",
    "    * Prepare reports or dashboards to visualize results.\n",
    "    * Communicate findings in a clear and actionable way, tailored to the audience (e.g., technical teams, business stakeholders).\n",
    "    * Provide documentation for reproducibility and future reference.\n",
    "\n",
    "12. Iterate and Improve\n",
    "\n",
    "* Objective: Continuously refine the workflow for better results.\n",
    "\n",
    "* Steps:\n",
    "\n",
    "    * Incorporate feedback from stakeholders and users.\n",
    "    * Iterate on feature engineering, model selection, or data collection as needed.\n",
    "    * Repeat the process to enhance accuracy, performance, or applicability.\n",
    "    \n",
    "By following these steps, a data science workflow ensures a systematic approach to solving problems and generating valuable insights from data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Give a real world example for each of the following data types:\n",
    "\n",
    "- record\n",
    "- graph\n",
    "- image\n",
    "- text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Record\n",
    "\n",
    "* Definition: A record is a structured data type that represents a single item in a dataset, typically consisting of multiple fields (attributes) with specific values.\n",
    "\n",
    "* Real-World Example:\n",
    "    * Medical Record: A patient's medical record in a hospital database, which includes fields like patient ID, name, date of birth, medical history, diagnosis, treatments, and test results. Each entry (record) corresponds to a unique patient.\n",
    "\n",
    "2. Graph\n",
    "* Definition: A graph is a data structure that represents entities (nodes) and the relationships (edges) between them. Graphs are used to model connections and interactions.\n",
    "\n",
    "* Real-World Example:\n",
    "    * Social Network: In a social media platform like Facebook, users are represented as nodes, and their friendships or connections are represented as edges. The graph structure enables analysis of social connections, like finding the shortest path between two users or identifying clusters of closely connected users (communities).\n",
    "\n",
    "3. Image\n",
    "* Definition: An image is a data type that represents visual information, typically in the form of pixels arranged in a grid, with each pixel containing color or grayscale information.\n",
    "\n",
    "* Real-World Example:\n",
    "    * MRI Scan: A medical imaging scan from an MRI machine used to diagnose health conditions. The image data represents different tissue types and abnormalities in the body and can be analyzed by radiologists or AI algorithms to detect diseases like tumors or fractures.\n",
    "\n",
    "4. Text\n",
    "* Definition: Text data consists of characters or words that convey information in a human-readable format. It can be structured (like a sentence) or unstructured (like a paragraph or document).\n",
    "\n",
    "* Real-World Example:\n",
    "    * Customer Reviews: Product reviews left by customers on an e-commerce platform like Amazon. Each review contains unstructured text data that can be analyzed for sentiment (positive, negative, neutral), trends, or specific feedback about the product.\n",
    "These examples illustrate the different types of data and how they are used in various real-world contexts to store, analyze, and derive meaningful insights.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) Give a real world example of unsupervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: Customer Segmentation in Marketing\n",
    "* Context: A retail company wants to better understand its customers to target them more effectively with personalized marketing campaigns and offers.\n",
    "* Data: The company collects data on customers' purchase history, browsing behavior, demographic information, frequency of visits, average purchase value, preferred product categories, and other relevant attributes.\n",
    "* Unsupervised Learning Technique:\n",
    "    * The company applies clustering algorithms (such as K-means, DBSCAN, or hierarchical clustering) to group customers into distinct segments based on similarities in their behaviors and characteristics.\n",
    "* Outcome:\n",
    "    * The clustering algorithm identifies patterns and groups customers into segments, such as:\n",
    "        * Frequent Shoppers: Customers who visit often and make small purchases.\n",
    "        * High-Value Customers: Customers who make large purchases occasionally.\n",
    "        * Bargain Hunters: Customers who primarily purchase items on sale or with discounts.\n",
    "        * New Customers: Customers who have recently joined and made few purchases.\n",
    "* Use Case:\n",
    "    * The company can use these segments to tailor marketing strategies:\n",
    "        * Send exclusive offers to high-value customers to increase loyalty.\n",
    "        * Offer discounts or promotions to bargain hunters to encourage repeat purchases.\n",
    "        * Provide personalized recommendations to new customers to boost engagement.\n",
    "* Benefits:\n",
    "    * Improved marketing efficiency, increased customer satisfaction, and better allocation of resources by understanding distinct customer needs and preferences.\n",
    "This is an example of unsupervised learning because there is no predefined label or category for customers; instead, the algorithm identifies patterns in the data without any prior knowledge of the segments."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g) Give a real world example of supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A real-world example of supervised learning is spam detection in email filtering.\n",
    "Example: Spam Detection in Email Filtering\n",
    "* Context: An email service provider, like Gmail or Outlook, wants to automatically filter out spam emails to improve user experience by keeping unwanted or malicious emails out of users' inboxes.\n",
    "* Data:\n",
    "    * The system is trained on a large labeled dataset of emails, where each email is marked as either \"spam\" or \"not spam.\"\n",
    "    * Features used for training may include the email content (words, phrases), sender's email address, subject line, presence of suspicious links, attachments, or specific patterns that are common in spam emails.\n",
    "* Supervised Learning Technique:\n",
    "    * The email service provider uses supervised learning algorithms, such as logistic regression, support vector machines (SVM), or neural networks, to learn patterns associated with spam and legitimate emails.\n",
    "    * The model is trained on the labeled dataset, learning the characteristics that differentiate spam emails from non-spam ones.\n",
    "* Outcome:\n",
    "    * The trained model can predict whether a new incoming email is spam or not based on its content and other features.\n",
    "    * If the model classifies an email as spam, it is moved to the \"Spam\" folder; otherwise, it is delivered to the user's inbox.\n",
    "* Use Case:\n",
    "    * The supervised learning model continually improves by retraining with new labeled data (emails marked by users as spam or not spam).\n",
    "    * Over time, the model becomes more accurate in identifying spam, reducing false positives (legitimate emails marked as spam) and false negatives (spam emails not detected).\n",
    "* Benefits:\n",
    "    * Enhanced email security by reducing the risk of phishing attacks or malicious content.\n",
    "    * Improved user experience by keeping the inbox clean and relevant.\n",
    "This example illustrates supervised learning because the model is trained on a labeled dataset where each email is explicitly marked as spam or not spam. The goal is for the model to learn from these examples to accurately classify new, unseen emails."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
